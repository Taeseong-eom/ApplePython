{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p1SFgoidIHJBG4HTrfKeR7_fizF6fmPH",
      "authorship_tag": "ABX9TyN1J+xW4OMO5+3RGKrKkLvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeseong-eom/ApplePython/blob/main/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKriq6rWsSJK",
        "outputId": "aaee5e0e-327e-44c2-b670-30d83047654f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "\n",
        "print(data.isnull().sum())\n",
        "# Age 칼럼에 빈칸이 177개라서  평균값을 넣었다.\n",
        "# 평균 = data['Age'].mean()\n",
        "# print(평균) # 29.69911764705882\n",
        "data['Age'].fillna(value=30, inplace=True) # 평균을 반올림 하여 적용하였다.\n",
        "\n",
        "# Embarked 칼럼도 2개가 최빈값으로 채우겠다.\n",
        "# 최빈값 = data['Embarked'].mode()\n",
        "# print(최빈값)\n",
        "data['Embarked'].fillna(value='S', inplace=True)\n",
        "\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpR4jFH_GY-j",
        "outputId": "8c3d1123-8fd6-443a-b86f-9ebbe0069c09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tf.data.Dataset.from_tensor_slices(X데이터, 정답) # 텐서플로우 데이터셋에 맞게 만들어줌\n",
        "# X 데이터는 정답을 제외한 모든 데이터고 정답데이터는 Survived 임.\n",
        "# 데이터를 그럼 분리를 해보자\n",
        "정답 = data.pop('Survived')\n",
        "train_size = int(0.8 * len(data))\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((dict(data[:train_size]), 정답[:train_size]))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((dict(data[train_size:]), 정답[train_size:]))\n",
        "\n",
        "# 지금까지는 [] 데이터만 학습데이터로 넣었는데 딕셔너리도 넣을 수 있다.\n",
        "print(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA-tjl-Lu7uh",
        "outputId": "d07985f6-09b7-4263-c92f-86930220706d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TensorSliceDataset element_spec=({'PassengerId': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Pclass': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Name': TensorSpec(shape=(), dtype=tf.string, name=None), 'Sex': TensorSpec(shape=(), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(), dtype=tf.float64, name=None), 'SibSp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Parch': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Ticket': TensorSpec(shape=(), dtype=tf.string, name=None), 'Fare': TensorSpec(shape=(), dtype=tf.float64, name=None), 'Embarked': TensorSpec(shape=(), dtype=tf.string, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# feature_column을 쓰려면 위에서 만든 ds처럼 데이터셋을 만들어야한다.\n",
        "# 필요 없는건 버리겠음. PassengerId\tName\n",
        "\n",
        "# 그대로 집어넣을꺼 SibSp\tParch Fare : numeric_column\n",
        "\n",
        "# 묶어서 넣을꺼 Age : bucketized_column\n",
        "\n",
        "# 카테고리/원핫인코딩할꺼(종류 몇개 없는거) Sex Embarked  : indicator_columnPclass\n",
        "\n",
        "# 종류가 많은거 Ticket : embedding_column # 하나의 행렬로 표현하고 무작위 숫자부여-> 학습할수록 값 조정\n",
        "\n",
        "feature_columns=[]\n",
        "feature_columns.append( tf.feature_column.numeric_column('Fare') )\n",
        "feature_columns.append( tf.feature_column.numeric_column('Parch'))\n",
        "feature_columns.append( tf.feature_column.numeric_column('SibSp'))\n",
        "\n",
        "Age = tf.feature_column.numeric_column('Age')\n",
        "Age_bucket = tf.feature_column.bucketized_column(Age, boundaries=[10,20,30,40,50,60]) # 10, 20, 30 대로 묶어줌.\n",
        "feature_columns.append( Age_bucket )\n",
        "\n",
        "print(Age)\n",
        "print(feature_columns)"
      ],
      "metadata": {
        "id": "6S4jOf1QxoOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9362fcf-5b9e-4d0b-8437-88749da17baa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
            "[NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(10, 20, 30, 40, 50, 60))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = data['Sex'].unique()\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocab) # 카테고리 나눌건데 뒤에 유니크한 리스트를 넣어야함.\n",
        "one_hot = tf.feature_column.indicator_column(cat)\n",
        "feature_columns.append(one_hot)\n",
        "\n",
        "vocab = data['Embarked'].unique()\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Embarked', vocab) # 카테고리 나눌건데 뒤에 유니크한 리스트를 넣어야함.\n",
        "one_hot = tf.feature_column.indicator_column(cat)\n",
        "feature_columns.append(one_hot)\n",
        "\n",
        "vocab = data['Pclass'].unique()\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Pclass', vocab) # 카테고리 나눌건데 뒤에 유니크한 리스트를 넣어야함.\n",
        "one_hot = tf.feature_column.indicator_column(cat)\n",
        "feature_columns.append(one_hot)\n",
        "\n",
        "\n",
        "#embedding\n",
        "vocab = data['Ticket'].unique()\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Ticket', vocab) # 카테고리 나눌건데 뒤에 유니크한 리스트를 넣어야함.\n",
        "one_hot = tf.feature_column.embedding_column(cat, dimension=9)\n",
        "feature_columns.append(one_hot)"
      ],
      "metadata": {
        "id": "9pEUqbGXM2mq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.DenseFeatures(feature_columns=feature_columns),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'), # 0 과 1 사이 출력\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "ds_batch =  train_ds.batch(32) # 32개씩 배치해줌.\n",
        "val_ds_batch = val_ds.batch(32)\n",
        "\n",
        "model.fit(ds_batch,validation_data=val_ds_batch ,shuffle=True, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or5M5hKaWUib",
        "outputId": "c1ce814c-c5ba-417b-b70b-4670fedfa65e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 2s 19ms/step - loss: 1.2258 - acc: 0.5449 - val_loss: 0.7912 - val_acc: 0.6480\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8570 - acc: 0.6334 - val_loss: 0.5157 - val_acc: 0.8156\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7354 - acc: 0.6980 - val_loss: 0.4758 - val_acc: 0.7933\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7399 - acc: 0.7191 - val_loss: 0.4320 - val_acc: 0.8101\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5846 - acc: 0.7598 - val_loss: 0.4322 - val_acc: 0.8156\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5676 - acc: 0.7697 - val_loss: 0.4142 - val_acc: 0.8212\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5239 - acc: 0.7935 - val_loss: 0.4035 - val_acc: 0.8324\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5469 - acc: 0.7963 - val_loss: 0.3992 - val_acc: 0.8324\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5089 - acc: 0.7879 - val_loss: 0.4228 - val_acc: 0.8156\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4873 - acc: 0.8048 - val_loss: 0.3907 - val_acc: 0.8268\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4650 - acc: 0.8104 - val_loss: 0.3887 - val_acc: 0.8212\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4367 - acc: 0.8329 - val_loss: 0.3813 - val_acc: 0.8268\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3978 - acc: 0.8371 - val_loss: 0.3866 - val_acc: 0.8380\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4080 - acc: 0.8497 - val_loss: 0.3781 - val_acc: 0.8380\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3636 - acc: 0.8539 - val_loss: 0.3819 - val_acc: 0.8324\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3202 - acc: 0.8820 - val_loss: 0.3853 - val_acc: 0.8324\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2976 - acc: 0.8876 - val_loss: 0.3901 - val_acc: 0.8268\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2841 - acc: 0.9003 - val_loss: 0.4038 - val_acc: 0.8212\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2435 - acc: 0.9031 - val_loss: 0.4136 - val_acc: 0.8268\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2442 - acc: 0.9171 - val_loss: 0.4294 - val_acc: 0.8212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79aba12c0130>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}