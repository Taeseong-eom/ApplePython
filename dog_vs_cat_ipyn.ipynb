{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NMMus4fSPhNt_XaFfNJa4Q1t0Wnubw7y",
      "authorship_tag": "ABX9TyMIMjyTOh8xe5kluOOjC38M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeseong-eom/ApplePython/blob/main/dog_vs_cat_ipyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtb--SXahy23",
        "outputId": "95635eac-febc-493f-87f2-ae3fea4524cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs-vs-cats-redux-kernels-edition.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os. environ['KAGGLE_CONFIG_DIR']= '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d ."
      ],
      "metadata": {
        "id": "F3XhDlMYnV7t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "BJKsnluiqIR3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "print (len(os.listdir('/content/train/'))) # 학습 이미지 개수가 2만5000개\n",
        "\n",
        "# 현재 train 폴더에는 개,고양이 사진이 같이 들어있다.\n",
        "# 개와 고양이 사진을 다른 폴더로 분류해보자.\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i: # 파일 이름에 'cat'이 들어있으면 '/content/dataset/cat/' + i 으로 복사해\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  elif 'dog' in i:# 파일 이름에 'dog'이 들어있으면 '/content/dataset/dog/' + i 으로 복사해\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLuUNthPqgzw",
        "outputId": "5bed2446-4a81-4a93-826e-fb8ee4add76f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 이미지를 숫자로 변환해야하는데 opencv라이브러리를 사용하거나\n",
        "# keras를 사용하면 변환할 수 있다.\n",
        "# keras가 간편하니 keras를 이용하겠다.\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory( # 아미지를 데이터셋 자료로 변환\n",
        "    '/content/dataset/', # 여기에 데이터들이 들어있어\n",
        "    image_size=(64,64), # 이미지 크기 조정\n",
        "    batch_size=64, # 이미지를 한번에 2만5천장을 넣지 않고 64장씩 넣겠다.\n",
        "    subset='training',# 데이터셋에서 20%를 valtidation으로 할당하겠다. 이름은 'training'으로 하겠다.\n",
        "    validation_split=0.2,\n",
        "    seed=1234,\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory( # 아미지를 데이터셋 자료로 변환\n",
        "    '/content/dataset/', # 여기에 데이터들이 들어있어\n",
        "    image_size=(64,64), # 이미지 크기 조정\n",
        "    batch_size=64,\n",
        "    subset='validation',\n",
        "    validation_split=0.2,\n",
        "    seed=1234,\n",
        ")\n",
        "print(train_ds)\n",
        "\n",
        "def 전처리함수(i, 정답):\n",
        "  i = tf.cast(i/255.0, tf.float32)\n",
        "  return i, 정답\n",
        "\n",
        "#숫자가 0 ~ 255 인걸 0 ~ 1로 압축을 하면 더 빨라진다.\n",
        "train_ds = train_ds.map(전처리함수) # train_ds의 데이터를 함수에 적용시켜라.\n",
        "val_ds = val_ds.map(전처리함수)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# # 데이터셋이 잘 변환되었는지 확인해보자\n",
        "# for i,정답 in train_ds.take(1): # 64개 데이터가 있는 데이터셋을 하나 가져옴.\n",
        "#   print(i)\n",
        "#   print(정답)\n",
        "#   plt.imshow(i[0].numpy().astype('uint8'))\n",
        "#   plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o76aEqFluR0R",
        "outputId": "049843e6-c8c3-43cc-9cf2-1f6395fe5ce6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu',input_shape=(64,64,3)),\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "    tf.keras.layers.Dropout(0.2), # Overfitting을 완화하기 위해 노트의 20%를 제거.\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'), # convolution을 많이 하면 정확도가 좋아\n",
        "    tf.keras.layers.MaxPool2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')# 0~1로 값 출력\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(train_ds,validation_data=val_ds,epochs=5) # 전처리를 안하면 학습속도, 정확도가 안좋다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F21wtJgh10AS",
        "outputId": "b208570d-d166-4ab8-dd24-bba851395c44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1142081 (4.36 MB)\n",
            "Trainable params: 1142081 (4.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "313/313 [==============================] - 233s 738ms/step - loss: 0.6316 - accuracy: 0.6308 - val_loss: 0.5640 - val_accuracy: 0.7072\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 227s 722ms/step - loss: 0.5152 - accuracy: 0.7459 - val_loss: 0.5213 - val_accuracy: 0.7414\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 225s 717ms/step - loss: 0.4526 - accuracy: 0.7888 - val_loss: 0.4799 - val_accuracy: 0.7788\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 218s 695ms/step - loss: 0.4083 - accuracy: 0.8116 - val_loss: 0.3955 - val_accuracy: 0.8236\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 223s 711ms/step - loss: 0.3670 - accuracy: 0.8348 - val_loss: 0.4299 - val_accuracy: 0.8068\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d74e04bee30>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}