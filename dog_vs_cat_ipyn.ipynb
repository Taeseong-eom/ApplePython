{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NMMus4fSPhNt_XaFfNJa4Q1t0Wnubw7y",
      "authorship_tag": "ABX9TyNbbwTX+T+DS8yDRtiyqiAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeseong-eom/ApplePython/blob/main/dog_vs_cat_ipyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtb--SXahy23",
        "outputId": "95635eac-febc-493f-87f2-ae3fea4524cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs-vs-cats-redux-kernels-edition.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os. environ['KAGGLE_CONFIG_DIR']= '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d ."
      ],
      "metadata": {
        "id": "F3XhDlMYnV7t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "BJKsnluiqIR3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "print (len(os.listdir('/content/train/'))) # 학습 이미지 개수가 2만5000개\n",
        "\n",
        "# 현재 train 폴더에는 개,고양이 사진이 같이 들어있다.\n",
        "# 개와 고양이 사진을 다른 폴더로 분류해보자.\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i: # 파일 이름에 'cat'이 들어있으면 '/content/dataset/cat/' + i 으로 복사해\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  elif 'dog' in i:# 파일 이름에 'dog'이 들어있으면 '/content/dataset/dog/' + i 으로 복사해\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLuUNthPqgzw",
        "outputId": "5bed2446-4a81-4a93-826e-fb8ee4add76f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 이미지를 숫자로 변환해야하는데 opencv라이브러리를 사용하거나\n",
        "# keras를 사용하면 변환할 수 있다.\n",
        "# keras가 간편하니 keras를 이용하겠다.\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory( # 아미지를 데이터셋 자료로 변환\n",
        "    '/content/dataset/', # 여기에 데이터들이 들어있어\n",
        "    image_size=(64,64), # 이미지 크기 조정\n",
        "    batch_size=64, # 이미지를 한번에 2만5천장을 넣지 않고 64장씩 넣겠다.\n",
        "    subset='training',# 데이터셋에서 20%를 valtidation으로 할당하겠다. 이름은 'training'으로 하겠다.\n",
        "    validation_split=0.2,\n",
        "    seed=1234,\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory( # 아미지를 데이터셋 자료로 변환\n",
        "    '/content/dataset/', # 여기에 데이터들이 들어있어\n",
        "    image_size=(64,64), # 이미지 크기 조정\n",
        "    batch_size=64,\n",
        "    subset='validation',\n",
        "    validation_split=0.2,\n",
        "    seed=1234,\n",
        ")\n",
        "print(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o76aEqFluR0R",
        "outputId": "85ed48c9-38fe-4ff1-9350-1add26e40cc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    }
  ]
}